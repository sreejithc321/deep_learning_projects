{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#### Predict based on diagnostic measurements whether a patient has diabetes\n",
    "\n",
    "Dataset Attributes\n",
    "==================\n",
    "Pregnancies: Number of times pregnant\n",
    "Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "BloodPressure: Diastolic blood pressure (mm Hg)\n",
    "SkinThickness: Triceps skin fold thickness (mm)\n",
    "Insulin: 2-Hour serum insulin (mu U/ml)\n",
    "BMI: Body mass index (weight in kg/(height in m)^2)\n",
    "DiabetesPedigreeFunction: Diabetes pedigree function\n",
    "Age: Age (years)\n",
    "Outcome: Class variable (0 or 1)\n",
    "\n",
    "Link : http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.data\", delimiter=\",\")\n",
    "features = dataset[:,0:8]\n",
    "output = dataset[:,8]\n",
    "print dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Model - multilayer perceptron\n",
    "def create_model( init= 'uniform', optimizer= 'adam', ):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, init='uniform', activation= 'relu'))\n",
    "    model.add(Dense(8, init= init , activation= 'relu' ))\n",
    "    model.add(Dense(1, init= init , activation= 'sigmoid' ))\n",
    "    model.compile(loss='binary_crossentropy' , optimizer= optimizer , metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.730519484439\n"
     ]
    }
   ],
   "source": [
    "# Fit and Evaluate Model\n",
    "model = KerasClassifier(build_fn=create_model, nb_epoch=100, batch_size=10, verbose=0)\n",
    "kfold = StratifiedKFold(y=output, n_folds=10, shuffle=True, random_state=10)\n",
    "results = cross_val_score(model, features, output, cv=kfold)\n",
    "print results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.755208344548 \t{'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 150, 'batch_size': 5}\n",
      "0.7031250117 \t0.0114996885424 \t{'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 50, 'batch_size': 5}\n",
      "0.699218762418 \t0.033753857921 \t{'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 50, 'batch_size': 5}\n",
      "0.720052095091 \t0.0192250303536 \t{'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 100, 'batch_size': 5}\n",
      "0.718750011331 \t0.0287049579945 \t{'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 100, 'batch_size': 5}\n",
      "0.7421875117 \t0.00318944014946 \t{'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 150, 'batch_size': 5}\n",
      "0.746093760885 \t0.0114996887467 \t{'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 150, 'batch_size': 5}\n",
      "0.699218761739 \t0.0063788788256 \t{'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 50, 'batch_size': 5}\n",
      "0.703125011506 \t0.0146158497997 \t{'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 50, 'batch_size': 5}\n",
      "0.722656263349 \t0.0177580483847 \t{'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 100, 'batch_size': 5}\n",
      "0.730468761428 \t0.0168769290817 \t{'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 100, 'batch_size': 5}\n",
      "0.739583344412 \t0.0226277949005 \t{'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 150, 'batch_size': 5}\n",
      "0.755208344548 \t0.0369663261482 \t{'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 150, 'batch_size': 5}\n",
      "0.705729178017 \t0.00368284785984 \t{'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 50, 'batch_size': 5}\n",
      "0.718750012224 \t0.0220970868709 \t{'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 50, 'batch_size': 5}\n",
      "0.743489594276 \t0.0230729750342 \t{'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 100, 'batch_size': 5}\n",
      "0.718750011545 \t0.0146158502975 \t{'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 100, 'batch_size': 5}\n",
      "0.752604178425 \t0.0239385103623 \t{'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 150, 'batch_size': 5}\n",
      "0.733072928522 \t0.0217100684305 \t{'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 150, 'batch_size': 5}\n",
      "0.72135416558 \t0.0289402467794 \t{'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 50, 'batch_size': 10}\n",
      "0.713541667986 \t0.0160531596657 \t{'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 50, 'batch_size': 10}\n",
      "0.713541668995 \t0.0235097251003 \t{'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 100, 'batch_size': 10}\n",
      "0.726562499767 \t0.025315393425 \t{'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 100, 'batch_size': 10}\n",
      "0.7421875 \t0.0304253113421 \t{'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 150, 'batch_size': 10}\n",
      "0.743489582868 \t0.0217100649162 \t{'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 150, 'batch_size': 10}\n",
      "0.690104165891 \t0.0102526098557 \t{'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 50, 'batch_size': 10}\n",
      "0.692708335662 \t0.0271258672705 \t{'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 50, 'batch_size': 10}\n",
      "0.710937500155 \t0.02491031877 \t{'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 100, 'batch_size': 10}\n",
      "0.70703125326 \t0.027804892328 \t{'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 100, 'batch_size': 10}\n",
      "0.71744791752 \t0.0314662637128 \t{'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 150, 'batch_size': 10}\n",
      "0.722656250931 \t0.00843846326548 \t{'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 150, 'batch_size': 10}\n",
      "0.691406250854 \t0.0481594832777 \t{'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 50, 'batch_size': 10}\n",
      "0.705729166899 \t0.0128899667068 \t{'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 50, 'batch_size': 10}\n",
      "0.713541668762 \t0.021236334799 \t{'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 100, 'batch_size': 10}\n",
      "0.70963541527 \t0.0338040473076 \t{'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 100, 'batch_size': 10}\n",
      "0.720052082945 \t0.0184142393678 \t{'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 150, 'batch_size': 10}\n",
      "0.73307291395 \t0.025976480126 \t{'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 150, 'batch_size': 10}\n",
      "0.684895832868 \t0.00802658201722 \t{'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 50, 'batch_size': 20}\n",
      "0.700520833954 \t0.011200948833 \t{'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 50, 'batch_size': 20}\n",
      "0.721354167908 \t0.00663935021235 \t{'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 100, 'batch_size': 20}\n",
      "0.716145834575 \t0.0271258652551 \t{'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 100, 'batch_size': 20}\n",
      "0.721354163873 \t0.0257799351071 \t{'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 150, 'batch_size': 20}\n",
      "0.714843748448 \t0.0249103222385 \t{'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 150, 'batch_size': 20}\n",
      "0.705729163873 \t0.0163669349705 \t{'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 50, 'batch_size': 20}\n",
      "0.703125002484 \t0.00637888372082 \t{'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 50, 'batch_size': 20}\n",
      "0.717447917598 \t0.0194877991384 \t{'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 100, 'batch_size': 20}\n",
      "0.72526041232 \t0.0132787004247 \t{'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 100, 'batch_size': 20}\n",
      "0.708333334886 \t0.00663934692469 \t{'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 150, 'batch_size': 20}\n",
      "0.704427084265 \t0.0319475119746 \t{'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 150, 'batch_size': 20}\n",
      "0.674479167598 \t0.0163669342296 \t{'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 50, 'batch_size': 20}\n",
      "0.699218747516 \t0.00318944623284 \t{'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 50, 'batch_size': 20}\n",
      "0.71484375 \t0.0063788829604 \t{'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 100, 'batch_size': 20}\n",
      "0.735677083644 \t0.0271258732125 \t{'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 100, 'batch_size': 20}\n",
      "0.71874999317 \t0.0223260761035 \t{'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 150, 'batch_size': 20}\n",
      "0.709635411389 \t0.0181359204528 \t{'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 150, 'batch_size': 20}\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "optimizers = ['rmsprop' , 'adam' ]\n",
    "init = ['glorot_uniform' , 'normal' , 'uniform' ]\n",
    "epochs = numpy.array([50, 100, 150])\n",
    "batches = numpy.array([5, 10, 20])\n",
    "param_grid = dict(optimizer=optimizers, nb_epoch=epochs, batch_size=batches, init=init)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(features, output)\n",
    "print grid_result.best_score_,'\\t', grid_result.best_params_\n",
    "for params, mean_score, scores in grid_result.grid_scores_:\n",
    "    print scores.mean(),'\\t', scores.std(),'\\t', params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
